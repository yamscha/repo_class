{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome('C:/Users/renuka/Desktop/chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://twitter.com/marswxreport?lang=en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://twitter.com/marswxreport?lang=en')\n",
    "soup= BeautifulSoup(driver.page_source,'lxml')\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question2: Mars Weather\n",
    "\n",
    "#####***** Visit the Mars Weather twitter account [here](https://twitter.com/marswxreport?lang=en)*************\n",
    "#####***** and scrape the latest Mars weather tweet from the page. \n",
    "#####***** Save the tweet text for the weather report as a variable called `mars_weather`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_weather = soup.select('.TweetTextSize')[0].text\n",
    "mars_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########***********end of solution2*********************###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 3 Mars Hemisperes\n",
    "\n",
    "#* Visit the USGS Astrogeology site [here](https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars) \n",
    "#to obtain high resolution images for each of Mar's hemispheres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome('C:/Users/renuka/Desktop/chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars')\n",
    "soup1= BeautifulSoup(driver.page_source,'lxml')\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list=[]\n",
    "for item in soup1.select('.description'):\n",
    "    name = item.select('h3')[0].text\n",
    "    name_list.append(name)\n",
    "    #print(name_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = soup1.find_all('div',class_='description')\n",
    "#one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in soup1.select('.description'):\n",
    "    link_list = item.select('.itemLink')\n",
    "    #name_list.append(name)\n",
    "    print(link_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url =[]\n",
    "for item in soup1.select('.description'):\n",
    "    #print(item.attrs['href'])\n",
    "    two_all = item.select('.itemLink')\n",
    "    for i in two_all:\n",
    "        image = i.attrs['href']\n",
    "        image_url.append(image)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_dict ={\"Ttile\":name_list,\n",
    "               \"url\":image_url,\n",
    "               }\n",
    "list_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_title = pd.DataFrame(list_to_dict)\n",
    "url_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if item.has_attr('href'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in soup.select('.thumb'):\n",
    "    if item.has_attr('src'):\n",
    "        print (item.attrs['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in soup.select('.item'):\n",
    "    image = item.select('.thumb')[0]\n",
    "    print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NASA Mars News\n",
    "\n",
    "#######* Scrape the [NASA Mars News Site](https://mars.nasa.gov/news/) \n",
    "######## and collect the latest News Title and Paragragh Text. Assign the text to variables that you can reference later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url ='https://mars.nasa.gov/news/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://mars.nasa.gov/news/')\n",
    "#response = requests.get()\n",
    "soup = BeautifulSoup(driver.page_source,\"lxml\")\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list =[]\n",
    "for item in soup.select('.list_text'):\n",
    "    title = item.select('.content_title')[0].text\n",
    "    title_list.append(title)\n",
    "    #print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_list =[]\n",
    "for item in soup.select('.list_text'):\n",
    "    para = item.select('.article_teaser_body')[0].text\n",
    "    para_list.append(para)\n",
    "    #print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for div in soup.find_all('div', class_=\"list_text\"):\n",
    "    para1 = div.find_all('div', class_=\"article_teaser_body\")[0].text\n",
    "    print(para1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_dict = {'Title':title_list,\n",
    "                'Paragraph':para_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#title = soup.select('.content_title')[0].text\n",
    "#title\n",
    "#para = soup.select('.article_teaser_body')[0].text\n",
    "#para\n",
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_data = pd.DataFrame(list_to_dict)\n",
    "para_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######************* End of solution1 *******###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pythondata]",
   "language": "python",
   "name": "conda-env-pythondata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
