{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_browser():\n",
    "    # @NOTE: Replace the path with your actual path to the chromedriver\n",
    "    executable_path = {\"executable_path\": 'C:/Users/renuka/Desktop/chromedriver.exe'}\n",
    "    return Browser(\"chrome\", **executable_path, headless=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape():\n",
    "    browser = init_browser()\n",
    "    listings = {}\n",
    "\n",
    "    #url = \"https://raleigh.craigslist.org/search/hhh?max_price=1500&availabilityMode=0\"\n",
    "    url= \"https://twitter.com/marswxreport?lang=en\"\n",
    "    browser.visit(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    listings[\"tweet\"]= soup.find('p',class_='TweetTextSize').get_text()\n",
    "    \n",
    "    #listings[\"headline\"] = soup.find(\"a\", class_=\"result-title\").get_text()\n",
    "    #listings[\"price\"] = soup.find(\"span\", class_=\"result-price\").get_text()\n",
    "    #listings[\"hood\"] = soup.find(\"span\", class_=\"result-hood\").get_text()\n",
    "\n",
    "    return listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                             ######app.py##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, jsonify, redirect\n",
    "from flask_pymongo import PyMongo\n",
    "#import scrape_craigslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "mongo = PyMongo(app)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/\")\n",
    "def index1():\n",
    "    listings = mongo.db.listings.find_one()\n",
    "    return render_template(\"index.html\", listings=listings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [17/Apr/2018 22:45:34] \"GET / HTTP/1.1\" 200 -\n",
      "[2018-04-17 22:45:37,228] ERROR in app: Exception on /scrape [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\renuka\\Anaconda3\\envs\\pythondata\\lib\\site-packages\\selenium\\webdriver\\common\\service.py\", line 76, in start\n",
      "    stdin=PIPE)\n",
      "  File \"C:\\Users\\renuka\\Anaconda3\\envs\\pythondata\\lib\\subprocess.py\", line 709, in __init__\n",
      "    restore_signals, start_new_session)\n",
      "  File \"C:\\Users\\renuka\\Anaconda3\\envs\\pythondata\\lib\\subprocess.py\", line 997, in _execute_child\n",
      "    startupinfo)\n",
      "FileNotFoundError: [WinError 2] The system cannot find the file specified\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\renuka\\Anaconda3\\envs\\pythondata\\lib\\site-packages\\flask\\app.py\", line 1982, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\renuka\\Anaconda3\\envs\\pythondata\\lib\\site-packages\\flask\\app.py\", line 1614, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\renuka\\Anaconda3\\envs\\pythondata\\lib\\site-packages\\flask\\app.py\", line 1517, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\renuka\\Anaconda3\\envs\\pythondata\\lib\\site-packages\\flask\\_compat.py\", line 33, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\renuka\\Anaconda3\\envs\\pythondata\\lib\\site-packages\\flask\\app.py\", line 1612, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\renuka\\Anaconda3\\envs\\pythondata\\lib\\site-packages\\flask\\app.py\", line 1598, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-7-31d840020f4c>\", line 4, in scrape1\n",
      "    listings_data = scrape_craigslist.scrape()\n",
      "  File \"C:\\Users\\renuka\\Documents\\NewREPO\\UCBSAN201801DATA2-Class-Repository-DATA\\13-Web-Scraping-and-Document-Databases\\3\\Activities\\Solved\\11-Ins_Scrape_And_Render\\scrape_craigslist.py\", line 15, in scrape\n",
      "    browser = init_browser()\n",
      "  File \"C:\\Users\\renuka\\Documents\\NewREPO\\UCBSAN201801DATA2-Class-Repository-DATA\\13-Web-Scraping-and-Document-Databases\\3\\Activities\\Solved\\11-Ins_Scrape_And_Render\\scrape_craigslist.py\", line 11, in init_browser\n",
      "    return Browser(\"chrome\", **executable_path, headless=False)\n",
      "  File \"C:\\Users\\renuka\\Anaconda3\\envs\\pythondata\\lib\\site-packages\\splinter\\browser.py\", line 63, in Browser\n",
      "    return driver(*args, **kwargs)\n",
      "  File \"C:\\Users\\renuka\\Anaconda3\\envs\\pythondata\\lib\\site-packages\\splinter\\driver\\webdriver\\chrome.py\", line 35, in __init__\n",
      "    self.driver = Chrome(chrome_options=options, **kwargs)\n",
      "  File \"C:\\Users\\renuka\\Anaconda3\\envs\\pythondata\\lib\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py\", line 68, in __init__\n",
      "    self.service.start()\n",
      "  File \"C:\\Users\\renuka\\Anaconda3\\envs\\pythondata\\lib\\site-packages\\selenium\\webdriver\\common\\service.py\", line 83, in start\n",
      "    os.path.basename(self.path), self.start_error_message)\n",
      "selenium.common.exceptions.WebDriverException: Message: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n",
      "\n",
      "127.0.0.1 - - [17/Apr/2018 22:45:37] \"GET /scrape HTTP/1.1\" 500 -\n",
      "127.0.0.1 - - [17/Apr/2018 22:46:32] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "@app.route(\"/scrape\")\n",
    "def scrape1():\n",
    "    listings = mongo.db.listings\n",
    "    #listings_data = scrape_craigslist.scrape()\n",
    "    listings_data = scrape()\n",
    "    listings.update(\n",
    "        {},\n",
    "        listings_data,\n",
    "        upsert=True\n",
    "    )\n",
    "    return redirect(\"http://localhost:5000/\", code=302)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pythondata]",
   "language": "python",
   "name": "conda-env-pythondata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
