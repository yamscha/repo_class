{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_browser():\n",
    "    # @NOTE: Replace the path with your actual path to the chromedriver\n",
    "    executable_path = {\"executable_path\": \"/usr/local/bin/chromedriver\"}\n",
    "    return Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape():\n",
    "    browser = init_browser()\n",
    "    # create surf_data dict that we can insert into mongo\n",
    "    surf_data = {}\n",
    "\n",
    "    # visit unsplash.com\n",
    "    unsplash = \"https://www.unsplash.com\"\n",
    "    browser.visit(unsplash)\n",
    "\n",
    "    # search for surfing\n",
    "    browser.fill(\"searchKeyword\", \"surfing\")\n",
    "\n",
    "    # find button and click it to search\n",
    "    button = browser.find_by_name(\"button\")\n",
    "    button.click()\n",
    "    time.sleep(2)\n",
    "    html = browser.html\n",
    "    # create a soup object from the html\n",
    "    img_soup = BeautifulSoup(html, \"html.parser\")\n",
    "    elem = img_soup.find(id=\"gridMulti\")\n",
    "    img_src = elem.find(\"img\")[\"src\"]\n",
    "\n",
    "    time.sleep(2)\n",
    "    # add our src to surf data with a key of src\n",
    "    surf_data[\"src\"] = img_src\n",
    "    # visit surfline to get weather report\n",
    "    weather = \"http://www.surfline.com/surf-forecasts/southern-california/santa-barbara_2141\"\n",
    "    browser.visit(weather)\n",
    "    # grab our new html from surfline\n",
    "    html = browser.html\n",
    "    # create soup object from html\n",
    "    forecast_soup = BeautifulSoup(html, \"html.parser\")\n",
    "    report = forecast_soup.find(class_=\"forecast-outlook\")\n",
    "    surf_report = report.find_all(\"p\")\n",
    "    # add it to our surf data dict\n",
    "    surf_data[\"report\"] = build_report(surf_report)\n",
    "    # return our surf data dict\n",
    "    return surf_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to build surf report\n",
    "def build_report(surf_report):\n",
    "    final_report = \"\"\n",
    "    for p in surf_report:\n",
    "        final_report += \" \" + p.get_text()\n",
    "        print(final_report)\n",
    "    return final_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pythondata]",
   "language": "python",
   "name": "conda-env-pythondata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
